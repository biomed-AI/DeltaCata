{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pubchempy as pcp\n",
    "\n",
    "from urllib import request\n",
    "from utils import *\n",
    "import ast\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17b9be",
   "metadata": {},
   "source": [
    "# 1. Download raw data from SABIO-RK\n",
    "Downloading data from SABIO-RK can take a couple of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ca3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_URL = 'http://sabiork.h-its.org/sabioRestWebServices/kineticlawsExportTsv'\n",
    "raw_data_save_path = \"./sabiork_data_cache/sabio_origin_file/\"\n",
    "os.makedirs(raw_data_save_path,exist_ok=True)\n",
    "file_list = os.listdir(raw_data_save_path) # Due to network instability, you can repeat several times to ensure that all data is downloaded\n",
    "for i in range(1,10):\n",
    "    for j in range(1,500):\n",
    "        EC=f\"{i}.{j}.*\"\n",
    "        if f\"EcNumber{i}.{j}.pkl\" in file_list:\n",
    "            continue\n",
    "        query_dict = {\"ECNumber\":'%s' %EC,}\n",
    "        query_string = ' AND '.join(['%s:%s' % (k,v) for k,v in query_dict.items()])\n",
    "        query = {'fields[]':['EntryID',\n",
    "                            'Substrate', 'ECNumber', 'Organism',\n",
    "                            'UniprotID', \n",
    "                            'EnzymeType', \n",
    "                            'PubMedID', 'SabioReactionID','KeggReactionID','Pathway', 'Buffer',\n",
    "                            'pH',\"temperature\", \n",
    "                            'Smiles',\n",
    "                            'Parameter' # kcat or Km value\n",
    "                            ], 'q':query_string}\n",
    "        request = requests.post(QUERY_URL, params = query)\n",
    "        if request.status_code == 200:\n",
    "            results = [i.split(\"\\t\") for i in request.text.split(\"\\n\")]\n",
    "            if len(results)>2:\n",
    "                print(f\"EcNumber{i}.{j}.pkl\")\n",
    "                pickle.dump(results,open(raw_data_save_path+f\"EcNumber{i}.{j}.pkl\",'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5228e",
   "metadata": {},
   "source": [
    "# 2. Data cleaning\n",
    "#### (a) Preprocess kcat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcat_entry_dict = {}\n",
    "for file in os.listdir(raw_data_save_path):\n",
    "    results = pickle.load(open(raw_data_save_path+file,'rb'))\n",
    "    for row in results[1:]:\n",
    "        if len(row)<20: # Missing data\n",
    "            continue\n",
    "        EC = row[2] \n",
    "        if sum([1 if len(i)>=1 else 0 for i in EC.split(\".\")])!=4: # EC exception. Example: 1.1.1. Entry id 56619\n",
    "            continue\n",
    "        # Missing kcat value\n",
    "        if row[14] == 'kcat' and row[16] == '': # Entry id 69933\n",
    "            continue\n",
    "        # Km-associated substrate is not in the substrate field above\n",
    "        subs = row[1].split(';')\n",
    "        if row[14] == 'Km' and row[15] not in subs: \n",
    "            continue\n",
    "        entryId = row[0]\n",
    "        if entryId not in kcat_entry_dict:\n",
    "            kcat_entry_dict[entryId] = []\n",
    "        kcat_entry_dict[entryId].append(row)\n",
    "len(kcat_entry_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcat_dataset = []\n",
    "for entryId,results in kcat_entry_dict.items():\n",
    "    EnzymeType = [row[14] for row in results]\n",
    "    \n",
    "    # Handling data with only one kcat value and at least one Km value.\n",
    "    if EnzymeType.count(\"kcat\")==1 and EnzymeType.count(\"Km\")>0: \n",
    "        kcat_row = [row for row in results if row[14]=='kcat'][0] \n",
    "        subs = [row[15] for row in results if row[14]=='Km'] \n",
    "        for sub in set(subs):\n",
    "            kcat_row_with_sub = list(kcat_row)\n",
    "            kcat_row_with_sub[15]=sub\n",
    "            kcat_dataset.append(kcat_row_with_sub)    \n",
    "            \n",
    "    # Handling data with no Km value, one kcat value, and only one substrate.\n",
    "    elif EnzymeType.count(\"kcat\")==1 and EnzymeType.count(\"Km\")==0:\n",
    "        sub = results[0][1].split(';')\n",
    "        if len(sub) != 1:\n",
    "            continue\n",
    "        sub = sub[0]\n",
    "        kcat_row = [row for row in results if row[14]=='kcat'][0] \n",
    "        kcat_row[15]=sub[0]\n",
    "        kcat_dataset.append(kcat_row)    \n",
    "    \n",
    "    # Handling data with multiple kcat values and at least one Km value.\n",
    "    elif EnzymeType.count(\"kcat\")>1 and EnzymeType.count(\"Km\")>0:\n",
    "        web_results = get_page_from_sabiork(entry)\n",
    "        results = entry_dict_multi_kcat[entry]\n",
    "        subs = [row[2] for row in web_results if row[1] == 'Km']\n",
    "        kcat_rows = [row for row in results if row[14] =='kcat' and row[19] == 's^(-1)']\n",
    "\n",
    "        if len(set(subs))==1: # only one substrate for different Km values\n",
    "            sub = subs[0]\n",
    "            kcat_row = kcat_rows[0]\n",
    "            kcat_row[16]=\",\".join([row[16] for row in kcat_rows])\n",
    "            kcat_row[15]=sub\n",
    "            kcat_dataset.append(kcat_row)\n",
    "        else:               \n",
    "            if 'kcat' in [row[0] for row in web_results]: # name cannot be mapped. e.g. Entry id 8246\n",
    "                continue\n",
    "            Km_tail = {row[0][-1]:row[2] for row in web_results if row[1] =='Km'} # Mapping substrate\n",
    "            kcat_tail={}\n",
    "            for row in web_results:\n",
    "                if row[6] not in ['min^(-1)','s^(-1)']:\n",
    "                    continue\n",
    "                kcat = str(round(float(row[3])/60,6)) if row[6]=='min^(-1)' else row[3]\n",
    "                kcat_tail[row[0][-1]]=kcat\n",
    "            if sum([1 for tail in kcat_tail if list(Km_tail.keys()).count(tail) != 1]) != 0: # name cannot be mapped. e.g. Entry id 5316, 3247\n",
    "                continue\n",
    "            for kcat_row in kcat_rows:\n",
    "                kcat_row_with_sub = list(kcat_row)\n",
    "\n",
    "                tail = [t for t,v in kcat_tail.items() if round(float(v),3) == round(float(kcat_row_with_sub[16]),3)][0]\n",
    "                sub = Km_tail[tail]\n",
    "                Km_tail.pop(tail)\n",
    "                kcat_tail.pop(tail)\n",
    "\n",
    "                kcat_row_with_sub[15]=sub\n",
    "                kcat_dataset.append(kcat_row_with_sub)\n",
    "    else:\n",
    "        continue\n",
    "len(kcat_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55994c7e",
   "metadata": {},
   "source": [
    "#### (b) Preprocess Km data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeff758",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_raw_dataset = []\n",
    "filelist = os.listdir(raw_data_save_path)\n",
    "need = []\n",
    "for file in filelist:\n",
    "    results = pickle.load(open(raw_data_save_path+file,'rb'))\n",
    "    if len(results[0])==19:\n",
    "        need.append(file.split('EcNumber')[1].split('.pkl')[0])\n",
    "        continue\n",
    "    for row in results[1:]:\n",
    "        if len(row)<20:\n",
    "            continue\n",
    "        if row[14] != 'Km':\n",
    "            continue\n",
    "        if sum([1 if len(i)>=1 else 0 for i in row[2].split(\".\")])!=4: # e.g. Entry id 56619\n",
    "            continue\n",
    "        if row[14] == 'Km' and row[16] == '':  # e.g. Entry id 69733\n",
    "            continue\n",
    "        subs = row[1].split(';')\n",
    "        if row[15] not in subs:\n",
    "            continue\n",
    "        if row[19] not in ['M','mg/ml'] :\n",
    "            continue\n",
    "        \n",
    "        km_raw_dataset.append(row)\n",
    "len(km_raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630bc4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_weight_dict = {}\n",
    "for row in km_raw_dataset:\n",
    "    if row[19] == 'mg/ml':\n",
    "        mol_weight_dict[row[15]]=-1\n",
    "\n",
    "for mol in tqdm(mol_weight_dict):\n",
    "    molecular_weight = get_mol_weight(mol)\n",
    "    if molecular_weight==-1:\n",
    "        continue\n",
    "    mol_weight_dict[mol]=molecular_weight\n",
    "\n",
    "km_dataset = []\n",
    "for raw_row in km_raw_dataset:\n",
    "    row = list(raw_row)\n",
    "    if row[19] == 'mg/ml':\n",
    "        molecular_weight = mol_weight_dict[row[15]]\n",
    "        if molecular_weight == -1:\n",
    "            continue\n",
    "        km_molar = float(row[16]) / (float(molecular_weight))\n",
    "        row[16]=km_molar*1000\n",
    "    elif row[19] == 'M':\n",
    "        row[16] = float(row[16])*1000\n",
    "    row[19]='mM'\n",
    "    km_dataset.append(row)\n",
    "len(km_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fcb78",
   "metadata": {},
   "source": [
    "#### (c) Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_PATTERN = re.compile(r'^[1-9]\\d*\\.(?:0|[1-9]\\d*)\\.(?:0|[1-9]\\d*)\\.(?:0|[1-9]\\d*)$')\n",
    "\n",
    "def is_valid_ec(ec):\n",
    "    if not isinstance(ec, str):\n",
    "        return False\n",
    "    ec = ec.strip()\n",
    "    return bool(EC_PATTERN.match(ec))\n",
    "\n",
    "kcat_dataset_clean=[row for row in kcat_dataset if row[4]!='' and len(row[4].split(\" \"))==1]\n",
    "kcat_dataset_clean=[row for row in kcat_dataset is_valid_ec(row[2])]\n",
    "kcat_dataset_clean=[row for row in kcat_dataset_clean if float(row[16])>0.00001 and float(row[16])<100000]\n",
    "\n",
    "km_dataset_clean=[row for row in km_dataset if row[4]!='' and len(row[4].split(\" \"))==1]\n",
    "km_dataset_clean=[row for row in km_dataset is_valid_ec(row[2])]\n",
    "km_dataset_clean=[row for row in km_dataset_clean if float(row[16])>0.00001 and float(row[16])<100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origin_cluster_dict(dataset):\n",
    "    field_loc = [2,3,4,6,15,8,10,11,12]    \n",
    "    cluster_dict = {}\n",
    "    for row in dataset:\n",
    "        pair_name = \";;;\".join([row[i] for i in field_loc])+';;;'+\";;;\".join(sorted(row[1].split(\";\")))+';;;'+\";;;\".join(sorted(row[13].split(\";\")))\n",
    "        if row[5].startswith(\"mutant\") and len(extract_mutations(row[5]))==0:\n",
    "            continue\n",
    "        if pair_name not in cluster_dict:\n",
    "            cluster_dict[pair_name]=[]\n",
    "        cluster_dict[pair_name].append(row)\n",
    "            \n",
    "    # Discard clusters containing only wild-type or only mutant entries.\n",
    "    for v in list(cluster_dict.keys()):\n",
    "        rows = cluster_dict[v]\n",
    "        type = [1 if row[5].startswith('mutant') else 2 for row in rows]\n",
    "        if type.count(1)>0 and type.count(2)>0:\n",
    "            continue\n",
    "        cluster_dict.pop(v)\n",
    "\n",
    "    return cluster_dict\n",
    "\n",
    "kcat_cluster_dict = get_origin_cluster_dict(kcat_dataset_clean)\n",
    "km_cluster_dict = get_origin_cluster_dict(km_dataset_clean)\n",
    "print(len(kcat_cluster_dict),len(km_cluster_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccacbb0c",
   "metadata": {},
   "source": [
    "# 3. Enzyme and substrate information retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2ea2b",
   "metadata": {},
   "source": [
    "#### (a) Download SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3956342",
   "metadata": {},
   "outputs": [],
   "source": [
    "Subs = [rows[0][15] for _,rows in kcat_cluster_dict.items()] + [rows[0][15] for _,rows in km_cluster_dict.items()]\n",
    "Subs = list(set(Subs))\n",
    "smiels_dict={}\n",
    "for sub in tqdm(Subs):\n",
    "    smiels_dict[sub]=get_comp(sub)\n",
    "    if smiels_dict[sub]==-1:\n",
    "        continue\n",
    "    smiles = smiels_dict[sub].canonical_smiles\n",
    "    if '.' in smiles:\n",
    "        smiels_dict[sub]=-1\n",
    "pickle.dump(smiels_dict,open(\"./sabiork_data_cache/smiles_dict.pkl\",'wb'))\n",
    "\n",
    "for cluster_name in list(kcat_cluster_dict.keys()):\n",
    "    if smiels_dict[kcat_cluster_dict[cluster_name][0][15]] == -1:\n",
    "        kcat_cluster_dict.pop(cluster_name)\n",
    "for cluster_name in list(km_cluster_dict.keys()):\n",
    "    if smiels_dict[km_cluster_dict[cluster_name][0][15]] == -1:\n",
    "        km_cluster_dict.pop(cluster_name)\n",
    "len(kcat_cluster_dict),len(km_cluster_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184c0f07",
   "metadata": {},
   "source": [
    "#### (b) Download sequences and verify mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16459806",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_aa = ['U','O','X','B','J','Z']\n",
    "def check_aa(seq):\n",
    "    for aa in seq:\n",
    "        if aa in error_aa:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "uniprotIds = list(set([rows[0][4] for _,rows in kcat_cluster_dict.items()] + [rows[0][4] for _,rows in km_cluster_dict.items()]))\n",
    "UID_Seq_dict = {}\n",
    "for id in tqdm(uniprotIds):\n",
    "    url = \"https://www.uniprot.org/uniprot/%s.fasta\" % id\n",
    "    try :\n",
    "        data = request.urlopen(url)\n",
    "        respdata = data.read().decode(\"utf-8\").strip()\n",
    "        seq = ''.join([i for i in respdata.split('\\n')[1:]])\n",
    "        if check_aa(seq):\n",
    "            UID_Seq_dict[id] = seq\n",
    "    except :\n",
    "        print(id, \"can not find from uniprot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mut_loc(cluster_dict):\n",
    "    for pair_name in list(cluster_dict.keys()):\n",
    "        rows = cluster_dict[pair_name]\n",
    "        wt_rows = [row for row in rows if row[5].startswith(\"wildtype\")]\n",
    "        mut_rows = [row for row in rows if row[5].startswith(\"mutant\")]\n",
    "        mut_rows_right_mut_loc = []\n",
    "        for row in mut_rows:\n",
    "            mut_loc = extract_mutations(row[5])\n",
    "            seq = IdSeq_dict[row[4]]\n",
    " \n",
    "            for dev in range(-1,2,1):\n",
    "                flag=True\n",
    "                for mut in mut_loc:\n",
    "                    loc = int(mut[1:-1])+dev\n",
    "                    if loc>len(seq) or mut[0] != seq[loc]:\n",
    "                        flag=False\n",
    "                        break\n",
    "                if flag:\n",
    "                    mut_rows_right_mut_loc.append(row)\n",
    "                    break\n",
    "        if len(mut_rows_right_mut_loc)==0:\n",
    "            cluster_dict.pop(pair_name)\n",
    "    return cluster_dict\n",
    "\n",
    "kcat_cluster_dict = check_mut_loc(kcat_cluster_dict)\n",
    "km_cluster_dict = check_mut_loc(km_cluster_dict)\n",
    "len(kcat_cluster_dict),len(km_cluster_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617aac6",
   "metadata": {},
   "source": [
    "# 4. Construct mutation effect pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97c7c6",
   "metadata": {},
   "source": [
    "#### (a) Deduplication\n",
    "Deduplication of multiple wildtypes or multiple identical mutant data within a cluster requires manual intervention to ensure accuracy. Here, we exported the comments in the clusters to a text file for manual processing when controversies existed. For example, some clusters may contain modified enzymes (indicated by suffixes), which should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99676379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cluster_multi_wt(cluster_dict):\n",
    "    for pair_name in list(cluster_dict.keys()):\n",
    "        rows = cluster_dict[pair_name]\n",
    "        wt_rows = [row for row in rows if row[5].startswith(\"wild\")]\n",
    "        mut_rows = [row for row in rows if row[5].startswith(\"mutant\")]\n",
    "        mut_locs = [\",\".join(extract_mutations(row[5])) for row in mut_rows]\n",
    "        \n",
    "        if len(wt_rows)>1:\n",
    "            print(wt_rows)\n",
    "            K = \",\".join([row[16] for row in wt_rows])\n",
    "            wt_rows[0][16] = K\n",
    "        wt_row = wt_rows[0]\n",
    "\n",
    "        if len(set(mut_locs))!= len(mut_locs):\n",
    "            grouped_mut_rows = [[row for row in mut_rows if \",\".join(extract_mutations(row[5]))==mut] for mut in set(mut_locs)]\n",
    "            mut_rows = []\n",
    "            for sub_grouped_mut_rows in grouped_mut_rows:\n",
    "                K = \",\".join([row[16] for row in sub_grouped_mut_rows])\n",
    "                sub_grouped_mut_rows[0][16] = K\n",
    "                mut_rows.append(sub_grouped_mut_rows[0])    \n",
    "        cluster_dict[pair_name] = [wt_row] + mut_rows\n",
    "    return cluster_dict\n",
    "    \n",
    "# The cluster here is the cluster that has been manually confirmed\n",
    "kcat_cluster_dict = remove_cluster_multi_wt(kcat_cluster_dict)\n",
    "km_cluster_dict = remove_cluster_multi_wt(km_cluster_dict)\n",
    "len(kcat_cluster_dict),len(km_cluster_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f687d2",
   "metadata": {},
   "source": [
    "#### (b) Create dataset and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_pairs(cluster_dict):\n",
    "    delta_pairs = []\n",
    "    for pair_name,rows in cluster_dict.items():\n",
    "        wt_row = [row for row in rows if row[5].startswith(\"wild\")][0]\n",
    "        mut_rows = [row for row in rows if row[5].startswith(\"mutant\")]\n",
    "        uniprotId = wt_row[4]\n",
    "        seq = IdSeq_dict[uniprotId]\n",
    "        for mut_row in mut_rows:\n",
    "            mut_loc = extract_mutations(mut_row[5])\n",
    "            for dev in range(-1,2,1):\n",
    "                flag=True\n",
    "                for mut in mut_loc:\n",
    "                    loc = int(mut[1:-1])+dev\n",
    "                    if loc>=len(seq) or mut[0] != seq[loc]:\n",
    "                        flag=False\n",
    "                        break\n",
    "                if flag: \n",
    "                    mut_loc_new = [mut[0]+str(int(mut[1:-1])+dev)+mut[-1] for mut in mut_loc]\n",
    "                    delta_pairs.append([wt_row,mut_row,mut_loc_new])\n",
    "                    break\n",
    "    return delta_pairs\n",
    "\n",
    "kcat_delta_pairs = form_pair(kcat_cluster_dict)\n",
    "km_delta_pairs = form_pair(km_cluster_dict)\n",
    "len(kcat_delta_pairs),len(km_delta_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(delta_pair,target):\n",
    "    EcNumber = []\n",
    "    organism = []\n",
    "    substrate = []\n",
    "    keggReactionId = []\n",
    "    UniprotId = []\n",
    "    pubmedId = []\n",
    "    temperature = []\n",
    "    pH = []\n",
    "    buffer = []\n",
    "\n",
    "    sequence = []\n",
    "    mutant = []\n",
    "    wt_ks = []\n",
    "    mut_ks = []\n",
    "    delta_ks = []\n",
    "    wt_entry = []\n",
    "    mut_entry = []\n",
    "\n",
    "    for wt_row,mut_row,mut_loc in delta_pair:\n",
    "        wt_K,mut_K = [float(i) for i in str(wt_row[16]).split(',')],[float(i) for i in str(mut_row[16]).split(',')]\n",
    "        wt_K = np.mean([math.log10(i) for i in wt_K])\n",
    "        mut_K = np.mean([math.log10(i) for i in mut_K])\n",
    "        \n",
    "        EcNumber.append(wt_row[2])\n",
    "        organism.append(wt_row[3].lower())\n",
    "        substrate.append(wt_row[15].lower())\n",
    "        keggReactionId.append(wt_row[8])\n",
    "        UniprotId.append(wt_row[4])\n",
    "        pubmedId.append(wt_row[6])\n",
    "        \n",
    "        temperature.append(str(float(wt_row[12])) if '-' not in wt_row[12] else '-')\n",
    "        pH.append(str(float(wt_row[11])) if '-' not in wt_row[11] else '-')\n",
    "        buffer.append(wt_row[10])\n",
    "\n",
    "        sequence.append(IdSeq_dict[wt_row[4]])\n",
    "        mutant.append(\",\".join(mut_loc))\n",
    "        wt_ks.append(wt_K)\n",
    "        mut_ks.append(mut_K)\n",
    "        delta_ks.append(mut_K-wt_K)\n",
    "        wt_entry.append(wt_row[0])\n",
    "        mut_entry.append(mut_row[0])\n",
    "    df = pd.DataFrame({\n",
    "        'EcNumber':EcNumber,'Organism':organism,\"Substrate\":substrate,\n",
    "        'KeggReactionId':keggReactionId,'UniprotId':UniprotId,'pubmedId':pubmedId,\n",
    "        'Temperature':temperature,'pH':pH,'buffer':buffer,\n",
    "        'sequence':sequence,'mutant':mutant,\n",
    "        f'wt_{target}_log10':wt_ks,f'mut_{target}_log10':mut_ks,f\"delta_{target}_log10\":delta_ks\n",
    "    })\n",
    "    return df\n",
    "\n",
    "delta_kcat_df = create_df(kcat_delta_pairs,'kcat')\n",
    "delta_km_df = create_df(km_delta_pairs,'km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_kcat_df = delta_kcat_df.groupby(['EcNumber', 'Organism','Substrate','KeggReactionId','UniprotId',\n",
    "                               'pubmedId','Temperature','pH','buffer','sequence','mutant',\n",
    "                               'wt_kcat_log10','mut_kcat_log10'], as_index=False).agg({'delta_kcat_log10': 'mean'})\n",
    "delta_km_df = delta_km_df.groupby(['EcNumber', 'Organism','Substrate','KeggReactionId','UniprotId',\n",
    "                               'pubmedId','Temperature','pH','buffer','sequence','mutant',\n",
    "                               'wt_km_log10','mut_km_log10'], as_index=False).agg({'delta_km_log10': 'mean'})\n",
    "\n",
    "delta_kcat_df.to_csv(\"./sabiork_data_cache/sabiork_delta_kcat_df.csv\",index=False)\n",
    "delta_km_df.to_csv(\"./sabiork_data_cache/sabiork_delta_km_df.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
